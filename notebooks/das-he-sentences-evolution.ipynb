{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ea0159",
   "metadata": {},
   "source": [
    "# DAS Evolution Queries - Sentences Dataset\n",
    "\n",
    "This notebook demonstrates how to use Evolution-based queries with Hyperon MeTTa and DAS.\n",
    "\n",
    "Evolution queries are like regular pattern-matching queries in the sense that it expects the same kind of input (a query) and delivers the same kind of result (an iterator to query answers). They are different because Evolution queries go through an evolutionary algorithm before delivering the answers while regular queries are simply executed in the query engine. Here's how it works.\n",
    "\n",
    "1. The caller submits a query to the evolution agent. In addition to the query itself, the caller also provides a fitness function, which can evaluate the quality of query answers giving a score in \\[0, 1\\], and a secondary query which we call the \"correlation query\", whose meaning will be explained below.\n",
    "2. The evolution agent will execute the query in the query engine and will use the first N results (N is another parameter of the evolution query request) to build a population of query answers.\n",
    "3. All the N query answers in the population are evaluated using the passed fitness function.\n",
    "4. The best M individuals (i.e. the M query answers with the largest fitness values) are selected to sample the next generation of the population (actually, the selection is made with a mix of just picking up the best individuals and tournament selection with the balance between them being another evolution parameter)\n",
    "5. To sample the population generation, first we use the \"correlation query\" passed as an evolution parameter. For each of the selected query answers, we use elements from the answer (variable values or the rewritten links themselves) to customize the correlation query. Then this query is executed in the query engine and its results are used to change the Hebbian Network related to the given context in the AttentionBroker and to stimulate some of the elements in the query answer. This stimulation will also trigger activation spreading in the Hebbian Network (all this stimulation and activation spreading happens ONLY IN ATTENTION BROKER, which keeps separate Hebbian Networks for different contexts; importance updating DOESN'T affect the atomspace itself).\n",
    "6. After the importance update in the context, the main query is executed once again and the next generation of the population is sampled by getting the best N individuals (query answers) as we did initially.\n",
    "7. Evolution query agent repeats steps 2-6 until a stop criteria (another evolution parameter) is met. While new generations are sampled and evaluated (using the passed fitness function), every time the agent sees a query answer which is better (i.e. has a larger fitness value) than the last one it delivered to the caller, this new best solution is instantly delivered (it doesn't matter if it is in the first generation, second or whatever). This way, in addition to the stop criteria passed as evolution parameter, the caller can also just interrupt the evolution process by aborting the query if it already found a solution which is considered good enough by the caller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8841c9",
   "metadata": {},
   "source": [
    "## Load Sentences Dataset (Optional)\n",
    "\n",
    "If not already loaded, use das-cli to load a sentences dataset containing 100K sentences with 10 words each (words starting with letters a-e).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e27beec-e2ad-4533-abb6-e2496126a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mdas-cli-mongodb-40021 is running on port 40021\u001b[0m\n",
      "\u001b[33mdas-cli-redis-40020 is running on port 40020\u001b[0m\n",
      "Loading metta file /tmp/100K_sentences_10_words_a-e.metta...\n",
      "Connecting to Redis at 0.0.0.0:40020\n",
      "Connecting to MongoDB at 0.0.0.0:40021\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!das-cli metta load /tmp/100K_sentences_10_words_a-e.metta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4759e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Initialize `hyperon` MeTTa environment and create a helper function to run MeTTa programs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8128ba3-3824-46ed-b40e-e4ceac7e9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperon\n",
    "\n",
    "metta = hyperon.MeTTa()\n",
    "def run(program='!(+ 1 2)'):\n",
    "    for result in metta.run(program):\n",
    "        for child in result:\n",
    "            print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4d681",
   "metadata": {},
   "source": [
    "## Import DAS Module\n",
    "\n",
    "Import the DAS module into the MeTTa environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b039a2-2953-4b9b-a167-2fb550e85b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "run('!(import! &self das)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e79f96",
   "metadata": {},
   "source": [
    "## Connect to DAS\n",
    "\n",
    "Bind a DAS connection to `&das` space. The first parameter specifies a client's host and port range (47000-47999) and the second must be a known peer address (eg. Query Agent at localhost:40002).\n",
    "\n",
    "For `MacOS` users you will need to use `host.docker.internal` as this notebook host (eg. `host.docker.internal:47000-47999`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9e3f76-19b9-4f7e-b8bd-9af8313b63d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "run('!(bind! &das (new-das! (localhost:47000-47999) (localhost:40002)))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebb8b5",
   "metadata": {},
   "source": [
    "## Check the available DAS services\n",
    "\n",
    "This command will return all available services as (endpoint \\<command\\>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dda15e6-0ab2-4940-9ace-d4f0b30b1eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "DAS Services (peer <command>) [5/5]:\n",
      "  - 0.0.0.0:40005 <query_evolution>\n",
      "  - 0.0.0.0:40004 <inference>\n",
      "  - 0.0.0.0:40003 <link_creation>\n",
      "  - 0.0.0.0:40006 <context>\n",
      "  - 0.0.0.0:40002 <pattern_matching_query>\n"
     ]
    }
   ],
   "source": [
    "run('!(das-services!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc59b9-b7a7-4377-9aec-6dd7c8ac219b",
   "metadata": {},
   "source": [
    "## Simple Query: Find Words in Sentence\n",
    "\n",
    "Find all words contained in a specific sentence. This is a basic pattern match to verify the dataset is loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330025dc-82df-4de6-8cb7-121f21d6678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bbe\"\n",
      "\"acc\"\n",
      "\"ceb\"\n",
      "\"cee\"\n",
      "\"cbe\"\n",
      "\"bbd\"\n",
      "\"ebe\"\n",
      "\"eec\"\n",
      "\"eaa\"\n",
      "\"bbb\"\n"
     ]
    }
   ],
   "source": [
    "run('!(match &das (Contains (Sentence \"acc eaa eec bbb bbe ceb cee cbe bbd ebe\") (Word $W)) $W)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849d7a4-d491-41c3-a300-e959815bdc38",
   "metadata": {},
   "source": [
    "## Create an Attention Broker Context\n",
    "\n",
    "Now we create a context in the Attention Broker (via Context Broker) that will be used by our evolution algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7aa11d-f4ab-435b-a546-81d1c745021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((name context) (key 5c18ef72771564b7f43c497dc507aeab))\n"
     ]
    }
   ],
   "source": [
    "run('!(das-create-context! context ((Contains $sentence1 $word1) ((0 $sentence1) ($sentence1 $word1)) ()))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11111950",
   "metadata": {},
   "source": [
    "## Define Evolution Query Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8284dfc-1133-46b2-a5e9-737aac0f9540",
   "metadata": {},
   "source": [
    "- **Query definition**: Pattern to search for sentences containing the word \"bbb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cd83e1-d500-4a8c-b443-75c768e361a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('''(= (query) (Contains $sentence1 (Word \"bbb\")))''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771fe7bf-d4d2-4064-b6fb-e6220fc2f3b2",
   "metadata": {},
   "source": [
    "- **Fitness function (ff)**: Fitness(sentence) = count(c, sentence) / length(sentence); count the occurrences of a given character and divide it by the sentence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbb439c-c98c-414a-a897-a5f089c7fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('''\n",
    "(= (str-length $s) (* ((py-dot \"\" len) $s) 1.0))\n",
    "(= (count-letters $s $c) (* ((py-dot $s count) $c) 1.0))\n",
    "(= (remove-spaces $s) ((py-dot $s replace) \" \" \"\"))\n",
    "(= (prep-sentence $s) (remove-spaces (index-atom $s 1)))\n",
    "(= \n",
    "  (ff $s $c) \n",
    "  (/ \n",
    "    (count-letters (prep-sentence $s) $c) \n",
    "    (str-length (prep-sentence $s))\n",
    "  )\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964de5cb-baee-4ba8-8a9a-87ba4052dbe2",
   "metadata": {},
   "source": [
    "- **Correlation parameters**: These parameters difine how the Hebbian network inside AttentionBroker should be updated in regard to each query answer of the main query above.\n",
    "\n",
    "For each query answer, `correlation-query` is used to make another query. Before being issued, elements of `correlation-query` are supposed to be replaced by elements in the query answer. These substitutions are determined by `correlation-replacements` which is basically a list of pairs with a mapping from elements in `correlation-query`which are supposed to be replaced by the corresponding element in the query answer.\n",
    "\n",
    "After being properly rewritten, `correlation-query` is issued and `correlation-mappings` is used to update the Hebbian Links. `correlation-mappings` is a list of pairs `(source, target)` where `source` is an element of the original query answer being correlated and `target` is an element of the `correlation-query` query answer. Each pair indicates that the corresponding Hebbian Link `source` -> `target` is supposed to be created in the proper context in the AttentionBroker (or updated to increase the link count by 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59fa9ef7-d2ac-4feb-a947-d2edc5fd33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run('''\n",
    "; Template queries used to find correlated atoms in the knowledge base after the initial query.\n",
    "(=\n",
    "  (correlation-queries)\n",
    "  (\n",
    "    (Contains $placeholder1 $word1)\n",
    "  )\n",
    ")\n",
    "\n",
    "; Variable substitution maps that specify which correlation query variables should be replaced \n",
    "; with actual values from the initial query answers.\n",
    "(=\n",
    "  (correlation-replacements)\n",
    "  (\n",
    "    (placeholder1 sentence1)\n",
    "  )\n",
    ")\n",
    "\n",
    "; Defines which elements from initial and correlation query answers should be linked together for \n",
    "; attention allocation updates (Hebbian Network).\n",
    "(=\n",
    "  (correlation-mappings)\n",
    "  (\n",
    "    (sentence1 word1)\n",
    "  )\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd9290",
   "metadata": {},
   "source": [
    "## Check Current Evolution Parameters\n",
    "\n",
    "Display the current DAS evolution parameters to see default settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36d7de1-3fc3-4b0b-b732-2254739ef358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "DAS Parameters:\n",
      "  Networking:\n",
      "    !(das-set-param! (hostname host.docker.internal))\n",
      "    !(das-set-param! (port_lower 47000))\n",
      "    !(das-set-param! (port_upper 47999))\n",
      "    !(das-set-param! (known_peer_id localhost:40002))\n",
      "  Context:\n",
      "    !(das-set-param! (context context))\n",
      "    !(das-set-param! (use_cache true))\n",
      "    !(das-set-param! (enforce_cache_recreation false))\n",
      "    !(das-set-param! (initial_rent_rate 0.25))\n",
      "    !(das-set-param! (initial_spreading_rate_lowerbound 0.5))\n",
      "    !(das-set-param! (initial_spreading_rate_upperbound 0.7))\n",
      "  Query:\n",
      "    !(das-set-param! (max_answers 100))\n",
      "    !(das-set-param! (max_bundle_size 1000))\n",
      "    !(das-set-param! (count_flag false))\n",
      "    !(das-set-param! (attention_update_flag false))\n",
      "    !(das-set-param! (unique_assignment_flag true))\n",
      "    !(das-set-param! (positive_importance_flag false))\n",
      "    !(das-set-param! (populate_metta_mapping true))\n",
      "    !(das-set-param! (use_metta_as_query_tokens true))\n",
      "  Evolution:\n",
      "    !(das-set-param! (elitism_rate 0.08))\n",
      "    !(das-set-param! (max_generations 10))\n",
      "    !(das-set-param! (population_size 50))\n",
      "    !(das-set-param! (selection_rate 0.1))\n",
      "    !(das-set-param! (total_attention_tokens 100000))\n",
      "  Link Creation:\n",
      "    !(das-set-param! (repeat_count 1))\n",
      "    !(das-set-param! (query_interval 0))\n",
      "    !(das-set-param! (query_timeout 0))\n"
     ]
    }
   ],
   "source": [
    "run('!(das-get-params!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2c52c",
   "metadata": {},
   "source": [
    "## Set Maximum Generations\n",
    "\n",
    "Configure the evolution to run for 5 generations only. Each generation refines the search based on correlation analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cfd5bb-af56-436c-a4ba-93d31ae9d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "DAS Param Updated: 'max_generations': UnsignedInt(5)\n"
     ]
    }
   ],
   "source": [
    "run('!(das-set-param! (max_generations 5))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e246b3",
   "metadata": {},
   "source": [
    "## Run Evolution Query\n",
    "\n",
    "Execute an evolution-based query that:\n",
    "1. Searches for sentences containing \"bbb\"\n",
    "2. Analyzes the frequency of letter \"c\" in matching sentences\n",
    "3. Evolves over 5 generations to find sentences with optimal \"c\" frequency\n",
    "4. Uses correlation mappings to refine results across generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0edf63-f66d-4f50-8044-91423c27ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sentence \"bbb bdb ddb aad bcb bbd dba ada aeb bbb\")\n",
      "(Sentence \"ebb abd dbe dde ebd abb ace bbb aba ebd\")\n",
      "(Sentence \"cdd bbb aab adb bea cbb dab eaa bbd bae\")\n",
      "(Sentence \"eae add bad acb aeb bbb cda bdb dbd dee\")\n",
      "(Sentence \"bbb eda ece eae eeb eae eab aca dda eed\")\n",
      "(Sentence \"eaa ddb aec ebe bde dae ebe add bbb cda\")\n",
      "(Sentence \"bbb cbb ecb bee dde ebc bad eeb bbe edb\")\n",
      "(Sentence \"cde eab ddd dbb eed ebe cde bbb ebb cad\")\n",
      "(Sentence \"cca cba aea bbb eea aee bdb aad aba ded\")\n",
      "(Sentence \"bdc bde bdd cee bee bbb bbd bee ebd dce\")\n",
      "(Sentence \"cbd bad bdb beb bcd bee caa aed bbb ade\")\n",
      "(Sentence \"eba cae dad bbb edd cdb aee bab abc bcb\")\n",
      "(Sentence \"deb aec bed bee bbb dea cec aca ddb beb\")\n",
      "(Sentence \"cbd bda ada ccd deb dae dbd dee cea bbb\")\n",
      "(Sentence \"dbe ebb eea ceb dcb ace aba bbb edc bed\")\n",
      "(Sentence \"aab dee aac cdc bea dba ecb ebd bbb dea\")\n",
      "(Sentence \"aee adc bbb abc eae aed dad acc daa bae\")\n",
      "(Sentence \"dbe cab eab dce dba bce eae bbb ded cba\")\n",
      "(Sentence \"bdb eea dcd ded eac eda bbb ceb bac eaa\")\n",
      "(Sentence \"dce bba edb dba aea bae bbb dcc bce abb\")\n",
      "(Sentence \"eae cce bbb ece bbb aad edc abd cea eea\")\n",
      "(Sentence \"cdb dbd ead aeb ade ada bbb cca cdb eac\")\n",
      "(Sentence \"adb bca bba ecb bbb ddb eab cdc bbe adc\")\n",
      "(Sentence \"caa ece bbb bac eba ede cbb aca aaa aee\")\n",
      "(Sentence \"bad ade bdb aca cbe bad dbc ccb bbb dae\")\n",
      "(Sentence \"edc bab aae cab aab edc bbb eea ced acd\")\n",
      "(Sentence \"cab bbb ece ddd cab cbc eba ebd dab ebe\")\n",
      "(Sentence \"acc bdb abb adc eee dca dba bbd bbb cbd\")\n",
      "(Sentence \"edd bea bce aec bdd aba dbc bbb aac acb\")\n",
      "(Sentence \"dee cda ded daa dcc aab dcc ebe eba bbb\")\n",
      "(Sentence \"cac ead ead abb eca dbe ece bbb cea beb\")\n",
      "(Sentence \"bce dcd cba aea eee eea aec bbb acb dad\")\n",
      "(Sentence \"eca ded bbb cbd bba dbc ecc eed aeb dec\")\n",
      "(Sentence \"acb bec cba edb eeb bdc bbb ede cbb cad\")\n",
      "(Sentence \"aca cee ced eee bbb cca baa add dba aec\")\n",
      "(Sentence \"cce dcc ddd bbb bad cae aad cde bda ede\")\n",
      "(Sentence \"beb aba aad dcc bbb cee cda bab cda dec\")\n",
      "(Sentence \"bee aaa beb acc bbb acd aeb bcc edd ccb\")\n",
      "(Sentence \"ccd ebe cde ddd bcd bbb cee aea bca aca\")\n",
      "(Sentence \"bbb bcb cdc cbc bab eba cea add eac dea\")\n",
      "(Sentence \"bdc dcd dca cce bbb aec bed ecb dee dda\")\n",
      "(Sentence \"dea dca cbd cce dbc bbb deb aed bcb aac\")\n",
      "(Sentence \"bbb ebc ecc daa bbe bda bbc dcd ccb dde\")\n",
      "(Sentence \"bbb ebe dcc abd cec dcd bba ccd beb cba\")\n",
      "(Sentence \"cdc ece cce bcb abd adb ddc eca bbb eda\")\n",
      "(Sentence \"bbc bbb cbb ced aae ccc bee cab abe ddc\")\n",
      "(Sentence \"dae dcd cbc ddc aab adc cbc bbb aea cdd\")\n",
      "(Sentence \"ddd aad ada dcc ccc eea ecd bbb abc cbe\")\n",
      "(Sentence \"bbd cca ade edc ace ecc ccd bbb ade cdd\")\n",
      "(Sentence \"bbb cad ebc dcb cec dae adc deb ccd cdc\")\n",
      "(Sentence \"edc dca abc bbb cbb eee cbc dcc ecc dbb\")\n",
      "(Sentence \"dca caa bbb cdc cda dce ced bbd bcd ecc\")\n",
      "(Sentence \"cad bdc abd ccc bdb ced dcd bbb dcd bcc\")\n",
      "(Sentence \"dce dcd aed bcb cda dcc cbc bbb dac dcd\")\n",
      "(Sentence \"ccb ccc cdd bbb dcc add ebe dbb dcd ecc\")\n",
      "(Sentence \"dec bbe ccb dec dda cca bbb bec cca ccc\")\n"
     ]
    }
   ],
   "source": [
    "run('''!(das-evolution! (!(query) (ff $sentence1 \"c\") !(correlation-queries) !(correlation-replacements) !(correlation-mappings)) $sentence1)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3ac14",
   "metadata": {},
   "source": [
    "## Test Fitness Function\n",
    "\n",
    "Calculate the frequency of letter \"c\" in the first and last two sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb0164e-5e87-4240-b8e4-031b8bddc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03333333333333333\n",
      "0.03333333333333333\n",
      "0.36666666666666664\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# First two senteces\n",
    "run('!(ff (Sentence \"bbb bdb ddb aad bcb bbd dba ada aeb bbb\") \"c\")')\n",
    "run('!(ff (Sentence \"ebb abd dbe dde ebd abb ace bbb aba ebd\") \"c\")')\n",
    "# Last two sentences\n",
    "run('!(ff (Sentence \"ccb ccc cdd bbb dcc add ebe dbb dcd ecc\") \"c\")')\n",
    "run('!(ff (Sentence \"dec bbe ccb dec dda cca bbb bec cca ccc\") \"c\")')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
